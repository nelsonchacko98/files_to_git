{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "d_oRUQmEOM75"
   },
   "outputs": [],
   "source": [
    "#pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MkGNwlPROSzw",
    "outputId": "c736c74e-b7a2-4123-e0e0-a90af73f38ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2WBZHGfHOS-L"
   },
   "outputs": [],
   "source": [
    "ner = nlp.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bH_XXypySjOM"
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA = [\n",
    "              (\"Walmart is a leading e-commerce company\", {\"entities\": [(0, 7, \"ORG\")]}),\n",
    "              (\"I reached Chennai yesterday.\", {\"entities\": [(19, 28, \"GPE\")]}),\n",
    "              (\"I recently ordered a book from Amazon\", {\"entities\": [(24,32, \"ORG\")]}),\n",
    "              (\"I was driving a BMW\", {\"entities\": [(16,19, \"PRODUCT\")]}),\n",
    "              (\"I ordered this from ShopClues\", {\"entities\": [(20,29, \"ORG\")]}),\n",
    "              (\"Fridge can be ordered in Amazon \", {\"entities\": [(0,6, \"PRODUCT\")]}),\n",
    "              (\"I bought a new Washer\", {\"entities\": [(16,22, \"PRODUCT\")]}),\n",
    "              (\"I bought a old table\", {\"entities\": [(16,21, \"PRODUCT\")]}),\n",
    "              (\"I bought a fancy dress\", {\"entities\": [(18,23, \"PRODUCT\")]}),\n",
    "              (\"I rented a camera\", {\"entities\": [(12,18, \"PRODUCT\")]}),\n",
    "              (\"I rented a tent for our trip\", {\"entities\": [(12,16, \"PRODUCT\")]}),\n",
    "              (\"I rented a screwdriver from our neighbour\", {\"entities\": [(12,22, \"PRODUCT\")]}),\n",
    "              (\"I repaired my computer\", {\"entities\": [(15,23, \"PRODUCT\")]}),\n",
    "              (\"I got my clock fixed\", {\"entities\": [(16,21, \"PRODUCT\")]}),\n",
    "              (\"I got my truck fixed\", {\"entities\": [(16,21, \"PRODUCT\")]}),\n",
    "              (\"Flipkart started it's journey from zero\", {\"entities\": [(0,8, \"ORG\")]}),\n",
    "              (\"I recently ordered from Max\", {\"entities\": [(24,27, \"ORG\")]}),\n",
    "              (\"Flipkart is recognized as leader in market\",{\"entities\": [(0,8, \"ORG\")]}),\n",
    "              (\"I recently ordered from Swiggy\", {\"entities\": [(24,29, \"ORG\")]})\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-hDLjOTRTq0w"
   },
   "outputs": [],
   "source": [
    "OurData = [(\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0zP4xUSMOTGQ"
   },
   "outputs": [],
   "source": [
    "for _, annotations in TRAIN_DATA:\n",
    "  for ent in annotations.get(\"entities\"):\n",
    "    ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PB8qsZkwR-fX"
   },
   "outputs": [],
   "source": [
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vOu3SnOOSHCN",
    "outputId": "3c115ae9-dac3-4824-898c-972d24fd8dcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3.7628068023223022}\n",
      "Losses {'ner': 4.97137270591702}\n",
      "Losses {'ner': 6.837301886987916}\n",
      "Losses {'ner': 8.134859696872809}\n",
      "Losses {'ner': 9.90261323606137}\n",
      "Losses {'ner': 2.372989619805594}\n",
      "Losses {'ner': 5.688270458265833}\n",
      "Losses {'ner': 10.10990089984989}\n",
      "Losses {'ner': 11.382781526073813}\n",
      "Losses {'ner': 14.857234546687323}\n",
      "Losses {'ner': 2.830343837267719}\n",
      "Losses {'ner': 4.878000189513841}\n",
      "Losses {'ner': 11.042186311875412}\n",
      "Losses {'ner': 11.062276639888296}\n",
      "Losses {'ner': 13.297297573613832}\n",
      "Losses {'ner': 5.080971277940421}\n",
      "Losses {'ner': 5.171745412032919}\n",
      "Losses {'ner': 8.19052974863314}\n",
      "Losses {'ner': 11.455174883779705}\n",
      "Losses {'ner': 11.676680631852264}\n",
      "Losses {'ner': 3.2333805411763024}\n",
      "Losses {'ner': 5.768409270678603}\n",
      "Losses {'ner': 5.792136508084695}\n",
      "Losses {'ner': 8.12762487870441}\n",
      "Losses {'ner': 11.886919942776537}\n",
      "Losses {'ner': 1.9303018717619125}\n",
      "Losses {'ner': 3.897699504803313}\n",
      "Losses {'ner': 3.9580082692154974}\n",
      "Losses {'ner': 8.524871211284335}\n",
      "Losses {'ner': 8.920925578701002}\n",
      "Losses {'ner': 3.6277378040540498}\n",
      "Losses {'ner': 4.216590451200261}\n",
      "Losses {'ner': 7.752997914792957}\n",
      "Losses {'ner': 9.970877661238262}\n",
      "Losses {'ner': 12.481954611981962}\n",
      "Losses {'ner': 2.008796500847893}\n",
      "Losses {'ner': 2.1143610294802784}\n",
      "Losses {'ner': 3.509199166981489}\n",
      "Losses {'ner': 7.863012792708105}\n",
      "Losses {'ner': 7.865923307403136}\n",
      "Losses {'ner': 0.4948007395946661}\n",
      "Losses {'ner': 1.8691792973772863}\n",
      "Losses {'ner': 2.3379368081000393}\n",
      "Losses {'ner': 4.264130197406757}\n",
      "Losses {'ner': 6.999279269873341}\n",
      "Losses {'ner': 0.3368076172043857}\n",
      "Losses {'ner': 1.4331340254427687}\n",
      "Losses {'ner': 1.5251144856717929}\n",
      "Losses {'ner': 3.5256958141083032}\n",
      "Losses {'ner': 4.119862643135377}\n",
      "Losses {'ner': 5.2132183082721895}\n",
      "Losses {'ner': 7.67415922357759}\n",
      "Losses {'ner': 7.675182467385866}\n",
      "Losses {'ner': 7.686237507533633}\n",
      "Losses {'ner': 8.261969491342143}\n",
      "Losses {'ner': 0.814459771435442}\n",
      "Losses {'ner': 2.7498586372012683}\n",
      "Losses {'ner': 4.752281591929077}\n",
      "Losses {'ner': 6.3950507585558265}\n",
      "Losses {'ner': 8.390866629170183}\n",
      "Losses {'ner': 0.07936122447159732}\n",
      "Losses {'ner': 2.9882460780052043}\n",
      "Losses {'ner': 3.449706081427948}\n",
      "Losses {'ner': 5.2612574141199815}\n",
      "Losses {'ner': 6.174201778584269}\n",
      "Losses {'ner': 1.5294501223262102}\n",
      "Losses {'ner': 1.5476680945104988}\n",
      "Losses {'ner': 1.5498480761368825}\n",
      "Losses {'ner': 1.934499044850142}\n",
      "Losses {'ner': 1.9345336291588406}\n",
      "Losses {'ner': 0.38793488513078955}\n",
      "Losses {'ner': 2.9852764468207624}\n",
      "Losses {'ner': 3.0295558666175455}\n",
      "Losses {'ner': 5.2274603089869185}\n",
      "Losses {'ner': 7.1853309428923104}\n",
      "Losses {'ner': 1.402942232798382e-05}\n",
      "Losses {'ner': 1.1076970714334549}\n",
      "Losses {'ner': 1.2296485904323673}\n",
      "Losses {'ner': 2.265388788718047}\n",
      "Losses {'ner': 2.2654817916052874}\n",
      "Losses {'ner': 1.5201798922748213}\n",
      "Losses {'ner': 1.5724081869998026}\n",
      "Losses {'ner': 1.9124937780875024}\n",
      "Losses {'ner': 4.510359492210516}\n",
      "Losses {'ner': 4.51145178312224}\n",
      "Losses {'ner': 1.680737411891009e-05}\n",
      "Losses {'ner': 1.8605572606631664}\n",
      "Losses {'ner': 1.9914502413091337}\n",
      "Losses {'ner': 1.9986460451261747}\n",
      "Losses {'ner': 1.998772972684097}\n",
      "Losses {'ner': 0.008609226463204535}\n",
      "Losses {'ner': 0.43582987535027856}\n",
      "Losses {'ner': 0.4925190480044946}\n",
      "Losses {'ner': 2.127329803151225}\n",
      "Losses {'ner': 2.2329845426130497}\n",
      "Losses {'ner': 1.683381999615908}\n",
      "Losses {'ner': 3.3826231719053683}\n",
      "Losses {'ner': 3.4196251506512687}\n",
      "Losses {'ner': 3.4244204666245657}\n",
      "Losses {'ner': 3.824486137392021}\n",
      "Losses {'ner': 1.009569131595995}\n",
      "Losses {'ner': 1.0229979646754994}\n",
      "Losses {'ner': 1.0233721115857242}\n",
      "Losses {'ner': 1.0276195193500897}\n",
      "Losses {'ner': 1.0387147172748321}\n",
      "Losses {'ner': 5.684512016712259e-05}\n",
      "Losses {'ner': 1.8719306749039801}\n",
      "Losses {'ner': 2.7560957300074924}\n",
      "Losses {'ner': 3.7940729341374198}\n",
      "Losses {'ner': 3.7941165901748546}\n",
      "Losses {'ner': 3.0801955237498513}\n",
      "Losses {'ner': 3.081126493297723}\n",
      "Losses {'ner': 4.3860013206519515}\n",
      "Losses {'ner': 4.710993219598279}\n",
      "Losses {'ner': 4.711007169463952}\n",
      "Losses {'ner': 1.9861703351331528e-05}\n",
      "Losses {'ner': 0.00014332031968189484}\n",
      "Losses {'ner': 0.00016326589650099985}\n",
      "Losses {'ner': 0.07356397281077869}\n",
      "Losses {'ner': 0.14520092590235129}\n",
      "Losses {'ner': 0.2634505664115444}\n",
      "Losses {'ner': 0.26379461840441676}\n",
      "Losses {'ner': 0.26379611657183116}\n",
      "Losses {'ner': 2.397238514449803}\n",
      "Losses {'ner': 2.6086166726421594}\n",
      "Losses {'ner': 0.030694634035794106}\n",
      "Losses {'ner': 0.24571323789144286}\n",
      "Losses {'ner': 1.4627413544652565}\n",
      "Losses {'ner': 1.475482276660106}\n",
      "Losses {'ner': 1.9176380383609277}\n",
      "Losses {'ner': 0.000989861921889365}\n",
      "Losses {'ner': 0.017321394643238272}\n",
      "Losses {'ner': 0.3707516449742995}\n",
      "Losses {'ner': 0.370752233665402}\n",
      "Losses {'ner': 0.3708037167598582}\n",
      "Losses {'ner': 0.10958873057953156}\n",
      "Losses {'ner': 1.7620300079265372}\n",
      "Losses {'ner': 1.7620813564562512}\n",
      "Losses {'ner': 1.7624685664195059}\n",
      "Losses {'ner': 1.7624692442887144}\n",
      "Losses {'ner': 1.4224732987842192}\n",
      "Losses {'ner': 2.2877577560001963}\n",
      "Losses {'ner': 2.446408909818849}\n",
      "Losses {'ner': 4.228012081081994}\n",
      "Losses {'ner': 4.22801210193614}\n",
      "Losses {'ner': 0.1951356984031783}\n",
      "Losses {'ner': 0.19599146013490837}\n",
      "Losses {'ner': 0.5136225707026076}\n",
      "Losses {'ner': 0.6527703678096007}\n",
      "Losses {'ner': 2.468065248391486}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "\n",
    "# TRAINING THE MODEL\n",
    "with nlp.disable_pipes(*unaffected_pipes):\n",
    "\n",
    "  # Training for 30 iterations\n",
    "  for iteration in range(30):\n",
    "\n",
    "    # shuufling examples  before every iteration\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "    # batch up the examples using spaCy's minibatch\n",
    "    batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "    for batch in batches:\n",
    "        texts, annotations = zip(*batch)\n",
    "        nlp.update(\n",
    "                    texts,  # batch of texts\n",
    "                    annotations,  # batch of annotations\n",
    "                    drop=0.5,  # dropout - make it harder to memorise data\n",
    "                    losses=losses,\n",
    "                )\n",
    "        print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Ly3IaBBSHD8",
    "outputId": "fbe4099b-93d3-4539-fe59-8268bd304b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Alto', 'PRODUCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I was driving a Alto\")\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Hrc3hvGSHHl",
    "outputId": "ae45577c-ab23-4f7f-c086-6ed3b60587d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to /dev/NER\n",
      "Loading from /dev/NER\n",
      "Entities [('Fridge', 'PRODUCT'), ('FlipKart', 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_dir = Path('/dev/NER')\n",
    "nlp.to_disk(output_dir)\n",
    "print(\"Saved model to\", output_dir)\n",
    "\n",
    "# Load the saved model and predict\n",
    "print(\"Loading from\", output_dir)\n",
    "nlp_updated = spacy.load(output_dir)\n",
    "doc = nlp_updated(\"Fridge can be ordered in FlipKart\" )\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "SpacyNer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
