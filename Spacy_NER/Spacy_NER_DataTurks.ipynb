{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Spacy_NER_DataTurks.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.6 64-bit ('venv': venv)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "cd74de847176a894e04f9f6398fca0ebd84e9e9765a87ee3e248947bb8ea563e"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib as ply\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "S34Rby3Qduha"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "import nltk\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk.tag import pos_tag"
      ],
      "outputs": [],
      "metadata": {
        "id": "z3cHUSJDdi3D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "import pandas as pd\r\n",
        "df = pd.read_json (r'Entity Recognition in Resumes.json',lines=True)\r\n",
        "df.to_csv (r'dataframe.csv', index = None)"
      ],
      "outputs": [],
      "metadata": {
        "id": "jcGSUP5beAqE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "import nltk\r\n",
        "\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('averaged_perceptron_tagger') \r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\nelson.c\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\nelson.c\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\nelson.c\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\nelson.c\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "metadata": {
        "id": "DAClJCNGg612"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "from nltk.corpus import stopwords\r\n",
        "import re\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "clean=[]"
      ],
      "outputs": [],
      "metadata": {
        "id": "iAnQgABOetxx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "for i in range(0,220):\r\n",
        "    review = re.sub('(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\"', ' ', df['content'][i])\r\n",
        "    review = review.lower()\r\n",
        "    review = review.split()\r\n",
        "    lm= WordNetLemmatizer() \r\n",
        "    review = [lm.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\r\n",
        "    review = ' '.join(review)\r\n",
        "    clean.append(review)"
      ],
      "outputs": [],
      "metadata": {
        "id": "eX8soikset44"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "df['cleaned']=clean"
      ],
      "outputs": [],
      "metadata": {
        "id": "20oBttRNifci"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "# df.head()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "akmRM1uzi8n0",
        "outputId": "d3006239-23a5-42a6-d4bf-2e6dd04e8f45"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "import spacy\r\n",
        "nlp = spacy.load('en_core_web_lg')\r\n",
        "from spacy.lang.en import English\r\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\r\n",
        "nlp = English()\r\n",
        "\r\n",
        "text = df['cleaned'][100]\r\n",
        "\r\n",
        "my_doc = nlp(text)"
      ],
      "outputs": [],
      "metadata": {
        "id": "OgUBQib-h5A-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "token_list = []\r\n",
        "for token in my_doc:\r\n",
        "    token_list.append(token.text)\r\n",
        "print(token_list)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za7XypRHjGWk",
        "outputId": "19ceb15a-fa23-4c20-e432-fe92c9f4136c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "import en_core_web_sm\r\n",
        "\r\n",
        "nlp = en_core_web_sm.load()\r\n",
        "\r\n",
        "docs = nlp(df['cleaned'][100])"
      ],
      "outputs": [],
      "metadata": {
        "id": "mqV5Fj7sjdut"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for word in docs:\r\n",
        "    print(word.text,word.pos_)"
      ],
      "outputs": [],
      "metadata": {
        "id": "n8bhgIHjjiBS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from spacy import displacy\r\n",
        "\r\n",
        "nytimes= nlp(df['cleaned'][100])\r\n",
        "\r\n",
        "entities=[(i, i.label_, i.label) for i in nytimes.ents]\r\n",
        "entities"
      ],
      "outputs": [],
      "metadata": {
        "id": "7BC3vhOcjx3y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "displacy.render(nytimes, style = \"ent\",jupyter = True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "bLtoavi_j4HS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "nytimes = nlp(\"sharon george pookkattu house pothanicad po pothanicad ernakulam dist kerala email sharongeorge72 gmailcom pin 686671 mob objectives seeking challenging career organization utilizes skills professional abilities trying reach maximum possible position providing abilities discharging duties integrity sincerity academic qualifications year degree institute passing nirmala mahatma gandhi mca college 2018 university muvattupuzha yeldo mar mahatma gandhi bca baselious 2015 university kothamangalam gov h higher secondary hse 2012 pallarimagalam board st joseph sslc hss state board 2010 paingottoor area interest programming software design development technical skills programming languages c java visual basic cobol php sql mysql internship details company name camerinflocks date 111118 01052019 subject java personal details name sharon george age date birth 25 16 1995 father name george p k gender female religion christian nationality indian mother tongue malayalam languages known english malayalam hindi declaration declare statements mentioned correct true best knowledge sharon george\")\r\n",
        "entities=[(i, i.label_, i.label) for i in nytimes.ents]\r\n",
        "displacy.render(nytimes, style = \"ent\",jupyter = True)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "GEJgX7bwkQI9",
        "outputId": "d541fe83-6112-4f63-8dcb-66415b3806a2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "nlp.to_disk(\"NerUpdated2\")"
      ],
      "outputs": [],
      "metadata": {}
    }
  ]
}